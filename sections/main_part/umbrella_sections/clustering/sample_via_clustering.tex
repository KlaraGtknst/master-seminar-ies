\subsection{Sample via clustering}
\label{subsec:SampleViaClustering}

The use of clustering methods to optimize \ac{cl} objectives is motivated by 
the requirement that positive pairs are located near each other in the embedding space, 
while negative pairs should be positioned further apart.
Intuitively, clusters of similar samples are considered positive samples.
Conversely, samples from different clusters are denoted negative samples.

Simple approaches, including \ac{drc} \citep{DRC_2020}, aim to create low intra-class diversity clusterings. 
To this end, they consider both the \ac{af}, i.e. a feature vector obtained from a \ac{cnn} with a fully connected layer, 
and the \ac{ap}, calculated via the softmax function of the \ac{af}, 
during clustering using a dedicated loss function.
This approach is motivated by their claim that existing methods cluster dissimilar \ac{af} together,
due to the usage of the maximum sensitivity of the softmax function used during cluster assignment.

In contrast to methods like \ac{drc}, \ac{swav} does not explicitly promote similar embeddings for positive pairs. 
Instead, it focuses on encouraging similar cluster assignments \citep{swav_2020}. 
The core idea is to swap the cluster assignments between two positive samples of the same image when calculating the loss, 
thereby promoting consistency in cluster assignments across similar instances. 
This approach indirectly aligns the embeddings of positive pairs by 
ensuring they are assigned to the same or similar clusters, 
rather than directly minimizing their distance in the embedding space.
A positive sample is obtained by applying a random augmentation to the anchor.

% interesting approaches
% Local Aggregation
\input{sections/main_part/negative_sampling_techniques/local_aggregation}

% Mining on manifolds
\input{sections/main_part/negative_sampling_techniques/mining_manifolds}

%PCL
\input{sections/main_part/negative_sampling_techniques/PCL}